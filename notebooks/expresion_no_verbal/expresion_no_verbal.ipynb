{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "099d5bdb",
   "metadata": {},
   "source": [
    "# Descargar los v√≠deos de YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "447a1e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîΩ Descargando: https://www.youtube.com/watch?v=rNwnEwlsNSA\n",
      "‚úÖ Descarga exitosa: tedtalk_rNwnEwlsNSA.webm (64.17 MB)    \n",
      "\n",
      "üîΩ Descargando: https://www.youtube.com/watch?v=5MgBikgcWnY\n",
      "‚úÖ Descarga exitosa: tedtalk_5MgBikgcWnY.webm (58.38 MB)    \n",
      "\n",
      "üî• Proceso de descarga completado\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yt_dlp\n",
    "import time\n",
    "\n",
    "# -------- CONFIGURACI√ìN --------\n",
    "video_urls = [\n",
    "    \"https://www.youtube.com/watch?v=rNwnEwlsNSA\",\n",
    "    \"https://www.youtube.com/watch?v=5MgBikgcWnY\",\n",
    "    # A√±ade aqu√≠ m√°s URLs de videos\n",
    "]\n",
    "\n",
    "raw_dir = \"data/raw\"\n",
    "processed_dir = \"data/processed\"\n",
    "os.makedirs(raw_dir, exist_ok=True)\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# -------- DESCARGAR VIDEOS --------\n",
    "for video_url in video_urls:\n",
    "    try:\n",
    "        # Extraer el ID del video para el nombre del archivo\n",
    "        with yt_dlp.YoutubeDL({'quiet': True}) as ydl:\n",
    "            info = ydl.extract_info(video_url, download=False)\n",
    "            video_id = info['id']\n",
    "            video_ext = info['ext']\n",
    "            \n",
    "        nombre_base = f\"tedtalk_{video_id}\"\n",
    "        input_path = os.path.join(raw_dir, f\"{nombre_base}.{video_ext}\")\n",
    "        output_path = os.path.join(processed_dir, f\"landmarks_{nombre_base}.mp4\")\n",
    "\n",
    "        if not os.path.exists(input_path):\n",
    "            print(f\"\\nüîΩ Descargando: {video_url}\")\n",
    "            ydl_opts = {\n",
    "                'outtmpl': input_path,\n",
    "                'format': 'mp4',\n",
    "                'quiet': True,\n",
    "            }\n",
    "            \n",
    "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "                ydl.download([video_url])\n",
    "            \n",
    "            # Verificar descarga exitosa\n",
    "            time.sleep(1)\n",
    "            if os.path.exists(input_path) and os.path.getsize(input_path) > 1024:\n",
    "                print(f\"‚úÖ Descarga exitosa: {os.path.basename(input_path)} \"\n",
    "                      f\"({os.path.getsize(input_path)/(1024*1024):.2f} MB)\")\n",
    "            else:\n",
    "                print(f\"‚ùå Error en descarga: {video_url}\")\n",
    "        else:\n",
    "            print(f\"üìÅ Archivo existente: {os.path.basename(input_path)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error procesando {video_url}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\nüî• Proceso de descarga completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12fb75d",
   "metadata": {},
   "source": [
    "# Procesamiento con MediaPipe Holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049034e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748284345.555286 2517962 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Max\n",
      "W0000 00:00:1748284345.648887 2552924 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1748284345.659763 2552924 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1748284345.660961 2552924 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1748284345.661011 2552926 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1748284345.661197 2552929 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1748284345.667657 2552929 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1748284345.667844 2552926 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1748284345.668599 2552922 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé• Procesando: tedtalk_5MgBikgcWnY.webm\n",
      "   Frame 34963/34963\n",
      "‚úÖ Guardado: data/processed/processed_000.mp4\n",
      "üìÑ Landmarks guardados en: data/processed/landmarks_csv/landmarks_000.csv\n",
      "\n",
      "üé• Procesando: tedtalk_rNwnEwlsNSA.webm\n",
      "   Frame 34814/34814\n",
      "‚úÖ Guardado: data/processed/processed_001.mp4\n",
      "üìÑ Landmarks guardados en: data/processed/landmarks_csv/landmarks_001.csv\n",
      "\n",
      "üéâ Todos los v√≠deos han sido procesados.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "\n",
    "# --- Rutas ---\n",
    "raw_dir = \"data/raw\"\n",
    "processed_dir = \"data/processed\"\n",
    "landmarks_dir = os.path.join(processed_dir, \"landmarks_csv\")\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "os.makedirs(landmarks_dir, exist_ok=True)\n",
    "\n",
    "# --- Inicializar MediaPipe Holistic ---\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "holistic = mp_holistic.Holistic(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=1,\n",
    "    smooth_landmarks=True,\n",
    "    enable_segmentation=False,\n",
    "    refine_face_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "# --- Obtener lista de v√≠deos .mp4 ---\n",
    "video_files = [f for f in os.listdir(raw_dir) if f.endswith(\".webm\")]\n",
    "if not video_files:\n",
    "    print(\"‚ö†Ô∏è No se encontraron videos en data/raw/\")\n",
    "else:\n",
    "    for idx, filename in enumerate(video_files):\n",
    "        video_id = f\"{idx:03d}\"\n",
    "        input_path = os.path.join(raw_dir, filename)\n",
    "        output_video = os.path.join(processed_dir, f\"processed_{video_id}.mp4\")\n",
    "        output_csv = os.path.join(landmarks_dir, f\"landmarks_{video_id}.csv\")\n",
    "\n",
    "        if os.path.exists(output_video) and os.path.exists(output_csv):\n",
    "            print(f\"üìÅ Ya procesado, saltando: {filename}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nüé• Procesando: {filename}\")\n",
    "        cap = cv2.VideoCapture(input_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"‚ùå No se pudo abrir: {input_path}\")\n",
    "            continue\n",
    "\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
    "\n",
    "        frame_count = 0\n",
    "        landmark_data = []\n",
    "\n",
    "        FRAME_SKIP = 2\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            if frame_count % FRAME_SKIP == 0:\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame_rgb.flags.writeable = False\n",
    "                results = holistic.process(frame_rgb)\n",
    "                frame.flags.writeable = True\n",
    "\n",
    "                # Dibujo\n",
    "                if results.face_landmarks:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        frame, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                        landmark_drawing_spec=mp_drawing.DrawingSpec(color=(255, 0, 255), thickness=1, circle_radius=1),\n",
    "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
    "\n",
    "                if results.left_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                        landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                        connection_drawing_spec=mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "                if results.right_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                        landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                        connection_drawing_spec=mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "                if results.pose_landmarks:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        frame, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                        landmark_drawing_spec=mp_drawing.DrawingSpec(color=(255, 255, 0), thickness=2, circle_radius=2),\n",
    "                        connection_drawing_spec=mp_drawing.DrawingSpec(color=(255, 255, 0), thickness=2, circle_radius=2))\n",
    "\n",
    "                out.write(frame)\n",
    "            \n",
    "            frame_count += 1\n",
    "\n",
    "            # Guardar landmarks como filas CSV\n",
    "            row = {\"frame\": frame_count}\n",
    "            for name, landmark_list in [(\"face\", results.face_landmarks),\n",
    "                                        (\"left_hand\", results.left_hand_landmarks),\n",
    "                                        (\"right_hand\", results.right_hand_landmarks),\n",
    "                                        (\"pose\", results.pose_landmarks)]:\n",
    "                if landmark_list:\n",
    "                    for i, lm in enumerate(landmark_list.landmark):\n",
    "                        row[f\"{name}_{i}_x\"] = lm.x\n",
    "                        row[f\"{name}_{i}_y\"] = lm.y\n",
    "                        row[f\"{name}_{i}_z\"] = lm.z\n",
    "                        row[f\"{name}_{i}_vis\"] = lm.visibility if name == \"pose\" else None\n",
    "            landmark_data.append(row)\n",
    "\n",
    "            frame_count += 1\n",
    "            print(f\"\\r   Frame {frame_count}/{total_frames}\", end=\"\")\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        print(f\"\\n‚úÖ Guardado: {output_video}\")\n",
    "\n",
    "        # Guardar CSV\n",
    "        df = pd.DataFrame(landmark_data)\n",
    "        df.to_csv(output_csv, index=False)\n",
    "        print(f\"üìÑ Landmarks guardados en: {output_csv}\")\n",
    "\n",
    "    holistic.close()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"\\nüéâ Todos los v√≠deos han sido procesados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76a563e",
   "metadata": {},
   "source": [
    "# Preprocesado de los .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88a0cea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'archivo': 'landmarks_000.csv', 'frames': 34963, 'columnas_finales': 1693},\n",
       " {'archivo': 'landmarks_001.csv', 'frames': 34814, 'columnas_finales': 1693}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Directorio donde est√°n los CSV de landmarks\n",
    "landmarks_dir = \"data/processed/landmarks_csv\"\n",
    "preprocessed_dir = \"data/processed/preprocessed_csv\"\n",
    "os.makedirs(preprocessed_dir, exist_ok=True)\n",
    "\n",
    "# Obtener lista de archivos CSV\n",
    "csv_files = [f for f in os.listdir(landmarks_dir) if f.endswith(\".csv\")]\n",
    "summary = []\n",
    "\n",
    "for filename in csv_files:\n",
    "    file_path = os.path.join(landmarks_dir, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Rellenar NaN con interpolaci√≥n (por columna)\n",
    "    df_interp = df.interpolate(method='linear', limit_direction='both', axis=0)\n",
    "\n",
    "    # Eliminar columnas con todos los valores nulos (por si hay landmarks no detectados nunca)\n",
    "    df_clean = df_interp.dropna(axis=1, how='all')\n",
    "\n",
    "    # Guardar CSV preprocesado\n",
    "    output_filename = f\"preprocessed_{filename}\"\n",
    "    output_path = os.path.join(preprocessed_dir, output_filename)\n",
    "    df_clean.to_csv(output_path, index=False)\n",
    "\n",
    "    summary.append({\"archivo\": filename, \"frames\": len(df), \"columnas_finales\": df_clean.shape[1]})\n",
    "\n",
    "display(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2074303a",
   "metadata": {},
   "source": [
    "# An√°lisis de ciertas m√©tricas de MediaPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a147ce81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>archivo</th>\n",
       "      <th>frames</th>\n",
       "      <th>mar_mean</th>\n",
       "      <th>wrist_y_mean</th>\n",
       "      <th>shoulder_dist_mean</th>\n",
       "      <th>movement_energy_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>preprocessed_landmarks_001.csv</td>\n",
       "      <td>34814</td>\n",
       "      <td>0.092059</td>\n",
       "      <td>0.654256</td>\n",
       "      <td>0.140813</td>\n",
       "      <td>0.111531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>preprocessed_landmarks_000.csv</td>\n",
       "      <td>34963</td>\n",
       "      <td>0.182070</td>\n",
       "      <td>0.679551</td>\n",
       "      <td>0.113705</td>\n",
       "      <td>0.119546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          archivo  frames  mar_mean  wrist_y_mean  \\\n",
       "0  preprocessed_landmarks_001.csv   34814  0.092059      0.654256   \n",
       "1  preprocessed_landmarks_000.csv   34963  0.182070      0.679551   \n",
       "\n",
       "   shoulder_dist_mean  movement_energy_mean  \n",
       "0            0.140813              0.111531  \n",
       "1            0.113705              0.119546  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# --- Ruta de entrada y salida ---\n",
    "preprocessed_dir = \"data/processed/preprocessed_csv\"\n",
    "metrics_dir = \"data/processed/metrics\"\n",
    "os.makedirs(metrics_dir, exist_ok=True)\n",
    "\n",
    "# --- Funciones auxiliares ---\n",
    "def calculate_mar(row):\n",
    "    try:\n",
    "        # MAR = distancia vertical / horizontal entre labios (usamos puntos aproximados)\n",
    "        top = np.array([row[\"face_13_x\"], row[\"face_13_y\"]])\n",
    "        bottom = np.array([row[\"face_14_x\"], row[\"face_14_y\"]])\n",
    "        left = np.array([row[\"face_61_x\"], row[\"face_61_y\"]])\n",
    "        right = np.array([row[\"face_291_x\"], row[\"face_291_y\"]])\n",
    "        vertical = np.linalg.norm(top - bottom)\n",
    "        horizontal = np.linalg.norm(left - right)\n",
    "        return vertical / horizontal if horizontal > 1e-6 else np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def average_wrist_y(row):\n",
    "    ys = []\n",
    "    for hand in [\"left_hand\", \"right_hand\"]:\n",
    "        key = f\"{hand}_0_y\"  # Landmark 0 = wrist\n",
    "        if key in row and not pd.isna(row[key]):\n",
    "            ys.append(row[key])\n",
    "    return np.mean(ys) if ys else np.nan\n",
    "\n",
    "def shoulder_distance(row):\n",
    "    try:\n",
    "        left = np.array([row[\"pose_11_x\"], row[\"pose_11_y\"]])  # Left shoulder\n",
    "        right = np.array([row[\"pose_12_x\"], row[\"pose_12_y\"]]) # Right shoulder\n",
    "        return np.linalg.norm(left - right)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def movement_energy(df, cols):\n",
    "    diffs = df[cols].diff().fillna(0)\n",
    "    energy = np.sqrt((diffs**2).sum(axis=1))\n",
    "    return energy.rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "# --- Procesar CSVs ---\n",
    "summary = []\n",
    "\n",
    "for filename in os.listdir(preprocessed_dir):\n",
    "    if not filename.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(preprocessed_dir, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # MAR\n",
    "    df[\"mar\"] = df.apply(calculate_mar, axis=1)\n",
    "\n",
    "    # Altura media mu√±ecas (indicador de gesticulaci√≥n)\n",
    "    df[\"avg_wrist_y\"] = df.apply(average_wrist_y, axis=1)\n",
    "\n",
    "    # Distancia entre hombros (postura abierta o cerrada)\n",
    "    df[\"shoulder_dist\"] = df.apply(shoulder_distance, axis=1)\n",
    "\n",
    "    # Energ√≠a de movimiento (sobre pose y manos)\n",
    "    movement_cols = [col for col in df.columns if any(k in col for k in [\"pose_\", \"left_hand_\", \"right_hand_\"]) and col.endswith(\"_x\") or col.endswith(\"_y\")]\n",
    "    df[\"movement_energy\"] = movement_energy(df, movement_cols)\n",
    "\n",
    "    # Guardar m√©tricas como CSV\n",
    "    output_path = os.path.join(metrics_dir, f\"metrics_{filename}\")\n",
    "    df[[\"frame\", \"mar\", \"avg_wrist_y\", \"shoulder_dist\", \"movement_energy\"]].to_csv(output_path, index=False)\n",
    "\n",
    "    summary.append({\n",
    "        \"archivo\": filename,\n",
    "        \"frames\": len(df),\n",
    "        \"mar_mean\": df[\"mar\"].mean(),\n",
    "        \"wrist_y_mean\": df[\"avg_wrist_y\"].mean(),\n",
    "        \"shoulder_dist_mean\": df[\"shoulder_dist\"].mean(),\n",
    "        \"movement_energy_mean\": df[\"movement_energy\"].mean()\n",
    "    })\n",
    "\n",
    "# Mostrar resumen de m√©tricas\n",
    "summary_df = pd.DataFrame(summary)\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae80466d",
   "metadata": {},
   "source": [
    "# Procesamiento con DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc70d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando frames:   4%|‚ñç         | 1392/34963 [00:40<07:18, 76.59it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from deepface import DeepFace\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Carpetas ---\n",
    "raw_dir = \"data/raw\"\n",
    "emotion_dir = \"data/processed/emotion_csv\"\n",
    "os.makedirs(emotion_dir, exist_ok=True)\n",
    "\n",
    "# --- Par√°metros ---\n",
    "FRAME_INTERVAL = 1  # segundos entre frames a analizar\n",
    "\n",
    "# --- Detectar v√≠deos ---\n",
    "video_files = [f for f in os.listdir(raw_dir) if f.endswith(\".webm\")]\n",
    "if not video_files:\n",
    "    print(\"‚ö†Ô∏è No se encontraron v√≠deos en data/raw/\")\n",
    "else:\n",
    "    for idx, filename in enumerate(video_files):\n",
    "        input_path = os.path.join(raw_dir, filename)\n",
    "        output_csv = os.path.join(emotion_dir, f\"emotions_{idx:03d}.csv\")\n",
    "\n",
    "        if os.path.exists(output_csv):\n",
    "            print(f\"üìÅ Ya procesado: {filename}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nüé• Analizando emociones en: {filename}\")\n",
    "        cap = cv2.VideoCapture(input_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"‚ùå No se pudo abrir: {input_path}\")\n",
    "            continue\n",
    "\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        duration = total_frames / fps if fps > 0 else 0\n",
    "        interval_frames = int(fps * FRAME_INTERVAL)\n",
    "\n",
    "        data = []\n",
    "\n",
    "        frame_id = 0\n",
    "        pbar = tqdm(total=total_frames, desc=\"Procesando frames\")\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret = cap.grab()  # avanzar al siguiente frame\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if frame_id % interval_frames == 0:\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                try:\n",
    "                    analysis = DeepFace.analyze(frame, actions=['emotion', 'age', 'gender'], enforce_detection=False)\n",
    "                    result = analysis[0] if isinstance(analysis, list) else analysis\n",
    "\n",
    "                    dominant_emotion = result[\"dominant_emotion\"]\n",
    "                    emotion_score = result[\"emotion\"][dominant_emotion]\n",
    "                    age = result.get(\"age\", None)\n",
    "                    gender = result.get(\"gender\", None)\n",
    "\n",
    "                    data.append({\n",
    "                        \"frame_id\": frame_id,\n",
    "                        \"timestamp_s\": frame_id / fps,\n",
    "                        \"dominant_emotion\": dominant_emotion,\n",
    "                        \"emotion_score\": emotion_score,\n",
    "                        \"age\": age,\n",
    "                        \"gender\": gender\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Error en frame {frame_id}: {e}\")\n",
    "\n",
    "            frame_id += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "        cap.release()\n",
    "        pbar.close()\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(output_csv, index=False)\n",
    "        print(f\"‚úÖ CSV guardado: {output_csv}\")\n",
    "\n",
    "print(\"\\nüéâ An√°lisis emocional terminado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyecto_final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
